{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backround"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article uses the highly used and preprocessed bioactivity dataset from the ChEMBL database, version 20. More specifically these seven different bioactivity classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Carbonic Anhydrase II (ChEMBL205), a protein lyase,  \n",
    "(b) Cyclin-dependent kinase 2 (CHEMBL301), a protein kinase,  \n",
    "(c) ether-a-go-go-related gene potassium channel 1 (HERG) (CHEMBL240), a voltage-gated ion channel,  \n",
    "(d) Dopamine D4 receptor (CHEMBL219), a monoamine GPCR,  \n",
    "(e) Coagulation factor X (CHEMBL244), a serine protease,  \n",
    "(f) Cannabinoid CB1 receptor (CHEMBL218), a lipid-like GPCR and  \n",
    "(g) Cytochrome P450 19A1 (CHEMBL1978), a cytochrome P450.  \n",
    "The activity classes were selected based on data availability and as representatives of therapeutically important target classes or as anti-targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will mainly focus on (a) the ChEMBL205 and (f) ChEMBL218 as these got quite different results from each other. Also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e12ef8f3464f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#hide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "path = Path('../dataset/13321_2017_226_MOESM1_ESM/')\n",
    "#df = pd.read_csv('../dataset/13321_2017_226_MOESM1_ESM/CHEMBL205_cl.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/13321_2017_226_MOESM1_ESM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cce31b23f0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#hide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/13321_2017_226_MOESM1_ESM'"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#df.head()\n",
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert the smiles from the dataset to ECFP fingerprint which is hashed into 1024 length bits. For this we made a function for creating a fingerprint using the methods from the RDKit library as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp(smile, diam = 2, bits = 1024):\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Chem.SanitizeMol(mol)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, diam, nBits = bits) \n",
    "    return fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a method for converting the csv with smiles to also have the fingerprint stored as colums from ECFP_1 to ECFP_1024 for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECFP4\n",
    "#Generated Circular fingerprints hashed into n bits length vectors.\n",
    "\n",
    "def ECFP(ifile, ofile, diam, bits):\n",
    "    \n",
    "    print(f\"Making fingerprints for file: {ifile}\")\n",
    "    df = pd.read_csv(ifile)\n",
    "    \n",
    "    df.insert(2, \"ECFP4_\", df.SMILES.apply(fp))\n",
    "    \n",
    "    df[[f\"ECFP4_{i+1}\" for i in range(len(df.ECFP4_[0]))]] = df.ECFP4_.to_list()\n",
    "    \n",
    "    df.drop(\"ECFP4_\", axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df.to_csv(path/ofile, index = None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can specify the dataset we want to use and to run the ECFP function on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='CHEMBL205_cl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "#ECFP(path/f'{dataset}.csv', f'./{dataset}_ecfp_1024.csv', 2, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a dataframe from the newly generated csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dac3d8b86b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{dataset}_ecfp_1024.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path/f'{dataset}_ecfp_1024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a74c58233b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"CID\", \"SMILES\", \"Activity\"], axis=1), df[\"Activity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17941 entries, 0 to 17940\n",
      "Columns: 1024 entries, ECFP4_1 to ECFP4_1024\n",
      "dtypes: int64(1024)\n",
      "memory usage: 140.2 MB\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: Activity, dtype: int64,\n",
       " 17941,\n",
       " pandas.core.series.Series)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "y.head(), y.size, type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follows the article where the data is split using 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, X_valid_list, y_train_list, y_valid_list = [], [], [], []\n",
    "\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_list.append(X_train.iloc[train_index])\n",
    "    X_valid_list.append(X_train.iloc[valid_index])\n",
    "    y_train_list.append(y_train.iloc[train_index])\n",
    "    y_valid_list.append(y_train.iloc[valid_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14960    0\n",
       "16280    0\n",
       "16068    0\n",
       "13692    0\n",
       "14043    0\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "y_train_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8611 entries, 14960 to 10114\n",
      "Columns: 1024 entries, ECFP4_1 to ECFP4_1024\n",
      "dtypes: int64(1024)\n",
      "memory usage: 67.3 MB\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "X_train_list[1].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from sklearn.metrics import auc,roc_auc_score,recall_score,precision_score,f1_score\n",
    "from  sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train method for Random Forest\n",
    "def train_rf(X_train, X_test, y_train, y_test, n_estimators=5, criterion='gini', max_features='log2'):\n",
    "\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, min_samples_split=2, max_features=max_features, \n",
    "                               max_leaf_nodes=None,bootstrap=False,oob_score=False, n_jobs=-1, random_state=69)\n",
    "    \n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred= rf.predict(X_test)\n",
    "    y_pred_prob=rf.predict_proba(X_test)\n",
    "    \n",
    "    temp=[]\n",
    "    for j in range(len(y_pred_prob)):\n",
    "        temp.append(y_pred_prob[j][1])\n",
    "    auc=roc_auc_score(np.array(y_test),np.array(temp))\n",
    "    acc2=accuracy_score(y_test,y_pred)\n",
    "    mcc=matthews_corrcoef(y_test,y_pred)\n",
    "    Recall=recall_score(y_test, y_pred,pos_label=1)\n",
    "    Precision=precision_score(y_test, y_pred,pos_label=1)\n",
    "    F1_score=f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "    return auc,acc2,mcc,Recall,Precision,F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation iteration: 1\n",
      "AUC score:0.9887427620260744\n",
      "Accuracy: 0.9730608453320948\n",
      "Matthews: 0.8415714713449818\n",
      "Recall: 0.8564356435643564\n",
      "Precision: 0.8564356435643564\n",
      "F1 score: 0.8564356435643564\n",
      "\n",
      "Cross validation iteration: 2\n",
      "AUC score:0.9876712143359863\n",
      "Accuracy: 0.9781699953553181\n",
      "Matthews: 0.8608807076715227\n",
      "Recall: 0.8563829787234043\n",
      "Precision: 0.8895027624309392\n",
      "F1 score: 0.8726287262872627\n",
      "\n",
      "Cross validation iteration: 3\n",
      "AUC score:0.9909322903664254\n",
      "Accuracy: 0.9712029725963771\n",
      "Matthews: 0.8122047591950275\n",
      "Recall: 0.8142076502732241\n",
      "Precision: 0.8418079096045198\n",
      "F1 score: 0.8277777777777778\n",
      "\n",
      "Cross validation iteration: 4\n",
      "AUC score:0.9754214676396435\n",
      "Accuracy: 0.9693450998606595\n",
      "Matthews: 0.8300350847464447\n",
      "Recall: 0.7964601769911505\n",
      "Precision: 0.9\n",
      "F1 score: 0.8450704225352113\n",
      "\n",
      "Cross validation iteration: 5\n",
      "AUC score:0.9912994366040052\n",
      "Accuracy: 0.9753717472118959\n",
      "Matthews: 0.8390326671715927\n",
      "Recall: 0.8406593406593407\n",
      "Precision: 0.864406779661017\n",
      "F1 score: 0.8523676880222841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train and print scores for each split\n",
    "for i in range(0,5):\n",
    "    \n",
    "    print(f'Cross validation iteration: {i + 1}')\n",
    "    \n",
    "    X_train = X_train_list[i]\n",
    "    X_valid = X_valid_list[i]\n",
    "    y_train = y_train_list[i]\n",
    "    y_valid = y_valid_list[i]\n",
    "    \n",
    "    auc,acc2,mcc,Recall,Precision,F1_score = train_rf(X_train, X_valid, y_train, y_valid, \n",
    "                                                      n_estimators=100, criterion='entropy', max_features='sqrt')\n",
    "    \n",
    "    print(f'AUC score:{auc}')\n",
    "    print(f'Accuracy: {acc2}')\n",
    "    print(f'Matthews: {mcc}')\n",
    "    print(f'Recall: {Recall}')\n",
    "    print(f'Precision: {Precision}')\n",
    "    print(f'F1 score: {F1_score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
